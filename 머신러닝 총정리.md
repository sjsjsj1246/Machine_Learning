# 머신러닝 정리

## 1. 거리 개념과 MDS

- 유사도를 거리개념으로 구하기
    - MDS : 관측값들 사이의 거리측도에 기초하여 관측값을 군집하는 기법
    - 민코우스키 거리 : 
        - 맨해튼 거리 : r=1
        - 유쿨리드 거리 : r=2

## 2. Decision Tree(의사결정 나무)

의사 결정 규칙과 그 결과들을 트리 구조로 도식화한 의사 결정 지원 도구의 일종.  

### 알고리즘고 수학적 정리

클로드새넌의 정보이론에 따른 엔트로피의 정의  
> Entropy(x)는 x에 대한 정보를 나타내기 위하여 평균적으로 알아야 할 bit의 개수이다. 이것은 정보의 기대값이다.  
결정트리에서 어떤 순서로 속성을 나눌지 판단할 떄는 정보 x의 엔트로피가 최소가 되는 속성을 선택하면 된다. 상태 변화에 따른 엔트로피의 변화량을 정보 이득이라 하며 다시말해 정보 이득을 높이는 방향으로 decision tree를 만들어 간다.  

### 코딩 구현

overfitting을 막기 위해 가지치기 기법을 사용하기도 한다. 자세한 방법은 통계학적으로 구할 수 있는데 이는 라이브러리가 다 해결해 준다.  

## 3. Clustering Analysis(군집 분석)

### 알고리즘과 수학적 정리

1. 계층적 군집
    데이터간의 거리를 구하여 연결
    군집 A{a, b}, B{c, d}
    - 최단 연결법 : 군집 사이의 데이터의 거리 중 최솟값 선택 d(AB) = min(d(a, c), d(a, d), d(b, c), d(b, d))
    - 최장 연결법 : 군집 사이의 데이터의 거리 중 최댓값 선택
    - 평균 연결법 : 군집A와 군집B의 거리의 합 / (군집A의 크기*군집B의 크기)
    - 중심 연결법 : A의 중심과 B의 중심 사이의 거리
    - 워드 연결법 : 음
2. K-means clustering
    1. 임의의 k개의 점 설정
    2. 점과 가까운 곳으로 데이터 분류
    3. 분류된 데이터에 대해 새로운 중심점 설정
    4. 2번부터 변동이 없을 때 까지 반복
    
    3번에서 중심점을 설정하는 방법이 평균이면 K-means, 중앙값이면 K-medianm, 이를 통틀어서 K-centroid clustering
3. DBSCAN
    데이터의 밀도를 이용하여 군집 형성

## 4. K-nearest neighbors

어떤 데이터의 라벨을 정의할 때 그 데이터의 주변 환경 안의 데이터들의 라벨들을 조사하여 k개 이상이고 가장 많은 것의 라벨로 정의하는 것

##